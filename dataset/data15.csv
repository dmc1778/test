23,keras.txt,https://api.github.com/repos/pronobis/libspn-keras/commits/0c3c4436e0b1c32f1528e07170cc74a313a4e051,libspn_keras/layers/root_sum.py,https://github.com/pronobis/libspn-keras/raw/0c3c4436e0b1c32f1528e07170cc74a313a4e051/libspn_keras/layers/root_sum.py," import tensorflow as tf\n \n from libspn_keras.logspace import logspace_wrapper_initializer\nfrom libspn_keras.math.logmatmul import logmatmul, logmatmul_hard_em_through_grads_from_accumulators\n+from libspn_keras.math.hard_em_grads import logmatmul_hard_em_through_grads_from_accumulators, logmultiply_hard_em\n from tensorflow import initializers\n \n+\n \n class RootSum(keras.layers.Layer):\n \n     def __init__(\n         self, return_weighted_child_logits=False, logspace_accumulators=False, hard_em_backward=False,\n        initializer=initializers.Constant(1.0)\n     ):\n         super(RootSum, self).__init__()\n         self._return_weighted_child_logits = return_weighted_child_logits\n         self._accumulators = self._num_nodes_in = None\n         self._logspace_accumulators = logspace_accumulators\n         self._hard_em_backward = hard_em_backward\n         self._initializer = initializer\n \n         if hard_em_backward and logspace_accumulators:\n             raise NotImplementedError(""Cannot use both Hard EM gradients and logspace accumulators"")\n \n        if hard_em_backward and return_weighted_child_logits:\n            raise NotImplementedError(""Cannot use both Hard EM gradients and weighted child logits"")\n+            raise NotImplementedError(""Cannot use both Soft EM gradients and logspace accumulators"")\n \n     def build(self, input_shape):\n         # Create a trainable weight variable for this layer."," import tensorflow as tf\n \n from libspn_keras.logspace import logspace_wrapper_initializer\nfrom libspn_keras.math.logmatmul import logmatmul\nfrom libspn_keras.math.hard_em_grads import logmatmul_hard_em_through_grads_from_accumulators, logmultiply_hard_em\n from tensorflow import initializers\n \nfrom libspn_keras.math.soft_em_grads import log_softmax_with_soft_em_grad\n\n \n class RootSum(keras.layers.Layer):\n \n     def __init__(\n         self, return_weighted_child_logits=False, logspace_accumulators=False, hard_em_backward=False,\n        initializer=initializers.Constant(1.0), soft_em_backward=False\n     ):\n         super(RootSum, self).__init__()\n         self._return_weighted_child_logits = return_weighted_child_logits\n         self._accumulators = self._num_nodes_in = None\n         self._logspace_accumulators = logspace_accumulators\n         self._hard_em_backward = hard_em_backward\n        self._soft_em_backward = soft_em_backward\n         self._initializer = initializer\n \n         if hard_em_backward and logspace_accumulators:\n             raise NotImplementedError(""Cannot use both Hard EM gradients and logspace accumulators"")\n \n-            raise NotImplementedError(""Cannot use both Hard EM gradients and weighted child logits"")\n        if soft_em_backward and logspace_accumulators:\n            raise NotImplementedError(""Cannot use both Soft EM gradients and logspace accumulators"")\n \n     def build(self, input_shape):\n         # Create a trainable weight variable for this layer.","from libspn_keras.math.logmatmul import logmatmul, logmatmul_hard_em_through_grads_from_accumulators\n        initializer=initializers.Constant(1.0)\n        if hard_em_backward and return_weighted_child_logits:\n            raise NotImplementedError(""Cannot use both Hard EM gradients and weighted child logits"")","from libspn_keras.math.logmatmul import logmatmul\nfrom libspn_keras.math.hard_em_grads import logmatmul_hard_em_through_grads_from_accumulators, logmultiply_hard_em\nfrom libspn_keras.math.soft_em_grads import log_softmax_with_soft_em_grad\n        initializer=initializers.Constant(1.0), soft_em_backward=False\n        self._soft_em_backward = soft_em_backward\n        if soft_em_backward and logspace_accumulators:\n            raise NotImplementedError(""Cannot use both Soft EM gradients and logspace accumulators"")",5,15,4,7
24,keras.txt,https://api.github.com/repos/pronobis/libspn-keras/commits/0c3c4436e0b1c32f1528e07170cc74a313a4e051,libspn_keras/layers/root_sum.py,https://github.com/pronobis/libspn-keras/raw/0c3c4436e0b1c32f1528e07170cc74a313a4e051/libspn_keras/layers/root_sum.py," \n         x_squeezed = tf.reshape(x, (-1, self._num_nodes_in))\n \n        log_weights_normalized = tf.nn.log_softmax(log_weights_unnormalized, axis=0)\n+            log_weights_normalized = log_softmax_with_soft_em_grad(self._accumulators, axis=0)\n+            log_weights_normalized = tf.nn.log_softmax(log_weights_unnormalized, axis=0)\n \n         if self._return_weighted_child_logits:\n             return tf.expand_dims(log_weights_normalized, axis=0) + x_squeezed"," \n         x_squeezed = tf.reshape(x, (-1, self._num_nodes_in))\n \n        if self._soft_em_backward:\n            log_weights_normalized = log_softmax_with_soft_em_grad(self._accumulators, axis=0)\n        else:\n            log_weights_normalized = tf.nn.log_softmax(log_weights_unnormalized, axis=0)\n \n         if self._return_weighted_child_logits:\n             return tf.expand_dims(log_weights_normalized, axis=0) + x_squeezed","        log_weights_normalized = tf.nn.log_softmax(log_weights_unnormalized, axis=0)","        if self._soft_em_backward:\n            log_weights_normalized = log_softmax_with_soft_em_grad(self._accumulators, axis=0)\n        else:\n            log_weights_normalized = tf.nn.log_softmax(log_weights_unnormalized, axis=0)",5,15,1,4
30,keras.txt,https://api.github.com/repos/entraned/keras/commits/15a3a1f1ce2a7babf62c61f73709c074249ed840,keras/utils/layer_utils.py,https://github.com/entraned/keras/raw/15a3a1f1ce2a7babf62c61f73709c074249ed840/keras/utils/layer_utils.py,"                     layer_dict[k] = regularizers.get(vname, v)\n \n         base_layer = get_layer(name, layer_dict)\n        if hasParams:\n            shaped_params = []\n            for param in params:\n                data = np.asarray(param.get('data'))\n                shape = tuple(param.get('shape'))\n                shaped_params.append(data.reshape(shape))\n            base_layer.set_weights(shaped_params)\n         return base_layer\n \n ","                     layer_dict[k] = regularizers.get(vname, v)\n \n         base_layer = get_layer(name, layer_dict)\n-            shaped_params = []\n-                data = np.asarray(param.get('data'))\n-                shaped_params.append(data.reshape(shape))\n         return base_layer\n \n ",        if hasParams:\n            shaped_params = []\n            for param in params:\n                data = np.asarray(param.get('data'))\n                shape = tuple(param.get('shape'))\n                shaped_params.append(data.reshape(shape))\n            base_layer.set_weights(shaped_params),,14,3,7,0
72,keras.txt,https://api.github.com/repos/Elizaaaaa/keras/commits/7fe2a04754e7a8d25f45a67a90e0ebd23beeed14,keras/preprocessing/image.py,https://github.com/Elizaaaaa/keras/raw/7fe2a04754e7a8d25f45a67a90e0ebd23beeed14/keras/preprocessing/image.py,"     x = np.rollaxis(x, channel_axis, 0)\n     min_x, max_x = np.min(x), np.max(x)\n    channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)\n                      for x_channel in x]\n+        np.clip(x_channel + np.random.uniform(-intensity, intensity),\n+                max_x)\n     x = np.stack(channel_images, axis=0)\n     x = np.rollaxis(x, 0, channel_axis + 1)\n     return x\n \n \n def random_brightness(x, brightness_range):\n    """"""Perform a random brightness shift.\n \n     # Arguments\n         x: Input tensor. Must be 3D.","     x = np.rollaxis(x, channel_axis, 0)\n     min_x, max_x = np.min(x), np.max(x)\n-                      for x_channel in x]\n    channel_images = [\n        np.clip(x_channel + np.random.uniform(-intensity, intensity),\n                min_x,\n                max_x)\n        for x_channel in x]\n     x = np.stack(channel_images, axis=0)\n     x = np.rollaxis(x, 0, channel_axis + 1)\n     return x\n \n \n def random_brightness(x, brightness_range):\n    """"""Performs a random brightness shift.\n \n     # Arguments\n         x: Input tensor. Must be 3D.","    channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)\n                      for x_channel in x]\n    """"""Perform a random brightness shift.","    channel_images = [\n        np.clip(x_channel + np.random.uniform(-intensity, intensity),\n                min_x,\n                max_x)\n        for x_channel in x]\n    """"""Performs a random brightness shift.",177,288,3,6
94,keras.txt,https://api.github.com/repos/cclamb/keras/commits/8a50f5dfc80030b864ef24d6c562661c24fe7c2e,keras/callbacks.py,https://github.com/cclamb/keras/raw/8a50f5dfc80030b864ef24d6c562661c24fe7c2e/keras/callbacks.py, from keras import backend as K\n from pkg_resources import parse_version\n \n+    import requests\n+    requests = None\n+if K.backend() == 'tensorflow':\n+\n \n class CallbackList(object):, from keras import backend as K\n from pkg_resources import parse_version\n \ntry:\n    import requests\nexcept ImportError:\n    requests = None\n\nif K.backend() == 'tensorflow':\n    import tensorflow as tf\n\n \n class CallbackList(object):,,try:\n    import requests\nexcept ImportError:\n    requests = None\nif K.backend() == 'tensorflow':\n    import tensorflow as tf,9,51,0,6
95,keras.txt,https://api.github.com/repos/allenai/deep_qa/commits/332217d3afd16d8371fdbaf00df87ec50b263ad7,src/main/python/deep_qa/layers/entailment_models.py,https://github.com/allenai/deep_qa/raw/332217d3afd16d8371fdbaf00df87ec50b263ad7/src/main/python/deep_qa/layers/entailment_models.py,"         '''\n         Takes a tensor and returns a matrix while preserving only the last dimension from the input.\n         '''\n        input_shape = K.shape(input_tensor)\n        last_dim = input_shape[-1]\n        size_till_last_dim = K.prod(input_shape[:-1])\n        return K.reshape(input_tensor, (size_till_last_dim, last_dim))\n+        shuffle_pattern = (input_ndim - 1,) + tuple(range(input_ndim - 1))\n+        return K.transpose(K.batch_flatten(dim_shuffled_input))\n \n     def call(self, x, mask=None):\n         # premise_length = hypothesis_length in the following lines, but the names are kept separate to keep","         '''\n         Takes a tensor and returns a matrix while preserving only the last dimension from the input.\n         '''\n-        last_dim = input_shape[-1]\n-        return K.reshape(input_tensor, (size_till_last_dim, last_dim))\n        input_ndim = K.ndim(input_tensor)\n        shuffle_pattern = (input_ndim - 1,) + tuple(range(input_ndim - 1))\n        dim_shuffled_input = K.permute_dimensions(input_tensor, shuffle_pattern)\n        return K.transpose(K.batch_flatten(dim_shuffled_input))\n \n     def call(self, x, mask=None):\n         # premise_length = hypothesis_length in the following lines, but the names are kept separate to keep","        input_shape = K.shape(input_tensor)\n        last_dim = input_shape[-1]\n        size_till_last_dim = K.prod(input_shape[:-1])\n        return K.reshape(input_tensor, (size_till_last_dim, last_dim))","        input_ndim = K.ndim(input_tensor)\n        shuffle_pattern = (input_ndim - 1,) + tuple(range(input_ndim - 1))\n        dim_shuffled_input = K.permute_dimensions(input_tensor, shuffle_pattern)\n        return K.transpose(K.batch_flatten(dim_shuffled_input))",20,38,4,4
176,keras.txt,https://api.github.com/repos/zoonn1788/TensorflowLiteDemo/commits/5082486121e539b6c002512f2a756e6b066696b4,tensorflow/python/kernel_tests/matrix_solve_ls_op_test.py,https://github.com/zoonn1788/TensorflowLiteDemo/raw/5082486121e539b6c002512f2a756e6b066696b4/tensorflow/python/kernel_tests/matrix_solve_ls_op_test.py,"       np_ans, _, _, _ = np.linalg.lstsq(a, b)\n       for fast in [True, False]:\n         with self.test_session():\n          tf_ans = tf.matrix_solve_ls(a, b, fast=fast).eval()\n        self.assertEqual(np_ans.shape, tf_ans.shape)\n+          ans = tf_ans.eval()\n+        self.assertEqual(np_ans.shape, ans.shape)\n \n         # Check residual norm.\n        tf_r = b - BatchMatMul(a, tf_ans)\n         tf_r_norm = np.sum(tf_r * tf_r)\n         np_r = b - BatchMatMul(a, np_ans)\n         np_r_norm = np.sum(np_r * np_r)","       np_ans, _, _, _ = np.linalg.lstsq(a, b)\n       for fast in [True, False]:\n         with self.test_session():\n-        self.assertEqual(np_ans.shape, tf_ans.shape)\n          tf_ans = tf.matrix_solve_ls(a, b, fast=fast)\n          ans = tf_ans.eval()\n        self.assertEqual(np_ans.shape, tf_ans.get_shape())\n        self.assertEqual(np_ans.shape, ans.shape)\n \n         # Check residual norm.\n        tf_r = b - BatchMatMul(a, ans)\n         tf_r_norm = np.sum(tf_r * tf_r)\n         np_r = b - BatchMatMul(a, np_ans)\n         np_r_norm = np.sum(np_r * np_r)","          tf_ans = tf.matrix_solve_ls(a, b, fast=fast).eval()\n        self.assertEqual(np_ans.shape, tf_ans.shape)\n        tf_r = b - BatchMatMul(a, tf_ans)","          tf_ans = tf.matrix_solve_ls(a, b, fast=fast)\n          ans = tf_ans.eval()\n        self.assertEqual(np_ans.shape, tf_ans.get_shape())\n        self.assertEqual(np_ans.shape, ans.shape)\n        tf_r = b - BatchMatMul(a, ans)",13,18,3,5
212,keras.txt,https://api.github.com/repos/BraunMichael/MultiResUNet-Keras-Dragonfly4.1/commits/15a3a1f1ce2a7babf62c61f73709c074249ed840,keras/utils/layer_utils.py,https://github.com/BraunMichael/MultiResUNet-Keras-Dragonfly4.1/raw/15a3a1f1ce2a7babf62c61f73709c074249ed840/keras/utils/layer_utils.py,"                     layer_dict[k] = regularizers.get(vname, v)\n \n         base_layer = get_layer(name, layer_dict)\n        if hasParams:\n            shaped_params = []\n            for param in params:\n                data = np.asarray(param.get('data'))\n                shape = tuple(param.get('shape'))\n                shaped_params.append(data.reshape(shape))\n            base_layer.set_weights(shaped_params)\n         return base_layer\n \n ","                     layer_dict[k] = regularizers.get(vname, v)\n \n         base_layer = get_layer(name, layer_dict)\n-            shaped_params = []\n-                data = np.asarray(param.get('data'))\n-                shaped_params.append(data.reshape(shape))\n         return base_layer\n \n ",        if hasParams:\n            shaped_params = []\n            for param in params:\n                data = np.asarray(param.get('data'))\n                shape = tuple(param.get('shape'))\n                shaped_params.append(data.reshape(shape))\n            base_layer.set_weights(shaped_params),,14,3,7,0
217,keras.txt,https://api.github.com/repos/CannyLab/rinokeras/commits/170c1ff8a0ca33658b82676274a98e9f8a277468,rinokeras/models/transformer.py,https://github.com/CannyLab/rinokeras/raw/170c1ff8a0ca33658b82676274a98e9f8a277468/rinokeras/models/transformer.py," \n             return i + 1, target_input, cache, output_sequence.write(i, tf.squeeze(output, 1))\n \n+        shapes = [inputs[0].shape, tf.TensorShape((None, None, initial_input.shape[-1])),\n         _, _, _, output_sequence = tf.while_loop(\n             lambda i, *_: i < max_seq_len,\n             decoding_step,\n            [tf.constant(0), initial_input, self.get_initial_cache(max_seq_len), output_sequence]\n+            shapes\n         )\n \n         output = tf.transpose(output_sequence.stack(), (1, 0, 2))"," \n             return i + 1, target_input, cache, output_sequence.write(i, tf.squeeze(output, 1))\n \n        inputs = [tf.constant(0), initial_input, self.get_initial_cache(max_seq_len), output_sequence]\n        shapes = [inputs[0].shape, tf.TensorShape((None, None, initial_input.shape[-1])),\n                  {name: getattr(el, 'shape', tf.TensorShape(None)) for name, el in inputs[2].items()}, tf.TensorShape(None)]\n         _, _, _, output_sequence = tf.while_loop(\n             lambda i, *_: i < max_seq_len,\n             decoding_step,\n            inputs,\n            shapes\n         )\n \n         output = tf.transpose(output_sequence.stack(), (1, 0, 2))","            [tf.constant(0), initial_input, self.get_initial_cache(max_seq_len), output_sequence]","        inputs = [tf.constant(0), initial_input, self.get_initial_cache(max_seq_len), output_sequence]\n        shapes = [inputs[0].shape, tf.TensorShape((None, None, initial_input.shape[-1])),\n                  {name: getattr(el, 'shape', tf.TensorShape(None)) for name, el in inputs[2].items()}, tf.TensorShape(None)]\n            inputs,\n            shapes",3,18,1,5
227,keras.txt,https://api.github.com/repos/reiserwang/keras/commits/8a50f5dfc80030b864ef24d6c562661c24fe7c2e,keras/callbacks.py,https://github.com/reiserwang/keras/raw/8a50f5dfc80030b864ef24d6c562661c24fe7c2e/keras/callbacks.py, from keras import backend as K\n from pkg_resources import parse_version\n \n+    import requests\n+    requests = None\n+if K.backend() == 'tensorflow':\n+\n \n class CallbackList(object):, from keras import backend as K\n from pkg_resources import parse_version\n \ntry:\n    import requests\nexcept ImportError:\n    requests = None\n\nif K.backend() == 'tensorflow':\n    import tensorflow as tf\n\n \n class CallbackList(object):,,try:\n    import requests\nexcept ImportError:\n    requests = None\nif K.backend() == 'tensorflow':\n    import tensorflow as tf,9,51,0,6
230,keras.txt,https://api.github.com/repos/keras-team/autokeras/commits/4b2a2f18a4da11d9573d341c38db2c754c77fff5,autokeras/utils.py,https://github.com/keras-team/autokeras/raw/4b2a2f18a4da11d9573d341c38db2c754c77fff5/autokeras/utils.py,"     return tf.compat.v1.data.get_output_shapes(dataset)\n \n \ndef inputs_to_datasets(x):\n    x = nest.flatten(x)\n    new_x = []\n    for temp_x in x:\n        if isinstance(temp_x, np.ndarray):\n            new_x.append(tf.data.Dataset.from_tensor_slices(temp_x))\n    return tf.data.Dataset.zip(tuple(new_x))\n\n\ndef prepare_preprocess(x, y):\n    """"""Convert each input to a tf.data.Dataset.""""""\n    x = inputs_to_datasets(x)\n    y = inputs_to_datasets(y)\n    return tf.data.Dataset.zip((x, y))\n\n\n def is_label(y):\n ","     return tf.compat.v1.data.get_output_shapes(dataset)\n \n \n-    x = nest.flatten(x)\n-    for temp_x in x:\n-            new_x.append(tf.data.Dataset.from_tensor_slices(temp_x))\n-def prepare_preprocess(x, y):\n-    x = inputs_to_datasets(x)\n-    return tf.data.Dataset.zip((x, y))\n-\n-\n def is_label(y):\n ","def inputs_to_datasets(x):\n    x = nest.flatten(x)\n    new_x = []\n    for temp_x in x:\n        if isinstance(temp_x, np.ndarray):\n            new_x.append(tf.data.Dataset.from_tensor_slices(temp_x))\n    return tf.data.Dataset.zip(tuple(new_x))\ndef prepare_preprocess(x, y):\n    """"""Convert each input to a tf.data.Dataset.""""""\n    x = inputs_to_datasets(x)\n    y = inputs_to_datasets(y)\n    return tf.data.Dataset.zip((x, y))",,35,41,12,0
242,keras.txt,https://api.github.com/repos/Yannick947/keras-retinanet/commits/9d2219d5e5f3e4139333d218bbea06ef92d0d917,keras_retinanet/losses.py,https://github.com/Yannick947/keras-retinanet/raw/9d2219d5e5f3e4139333d218bbea06ef92d0d917/keras_retinanet/losses.py,"         cls_loss = cls_loss / divisor\n \n         # filter out ""ignore"" anchors\n        anchor_state   = keras.backend.max(labels, axis=2)  # -1 for ignore, 0 for background, 1 for object\n        indices        = keras_retinanet.backend.where(keras.backend.not_equal(anchor_state, -1))\n+        indices      = keras_retinanet.backend.where(keras.backend.not_equal(anchor_state, -1))\n \n         cls_loss = keras_retinanet.backend.gather_nd(cls_loss, indices)\n \n         # divide by the size of the minibatch\n        return keras.backend.sum(cls_loss) / keras.backend.cast(keras.backend.shape(y_true)[0], keras.backend.floatx())\n \n     return _focal\n ","         cls_loss = cls_loss / divisor\n \n         # filter out ""ignore"" anchors\n-        indices        = keras_retinanet.backend.where(keras.backend.not_equal(anchor_state, -1))\n        anchor_state = keras.backend.max(labels, axis=2)  # -1 for ignore, 0 for background, 1 for object\n        indices      = keras_retinanet.backend.where(keras.backend.not_equal(anchor_state, -1))\n \n         cls_loss = keras_retinanet.backend.gather_nd(cls_loss, indices)\n \n         # divide by the size of the minibatch\n        return keras.backend.sum(cls_loss) / keras.backend.cast(keras.backend.shape(labels)[0], keras.backend.floatx())\n \n     return _focal\n ","        anchor_state   = keras.backend.max(labels, axis=2)  # -1 for ignore, 0 for background, 1 for object\n        indices        = keras_retinanet.backend.where(keras.backend.not_equal(anchor_state, -1))\n        return keras.backend.sum(cls_loss) / keras.backend.cast(keras.backend.shape(y_true)[0], keras.backend.floatx())","        anchor_state = keras.backend.max(labels, axis=2)  # -1 for ignore, 0 for background, 1 for object\n        indices      = keras_retinanet.backend.where(keras.backend.not_equal(anchor_state, -1))\n        return keras.backend.sum(cls_loss) / keras.backend.cast(keras.backend.shape(labels)[0], keras.backend.floatx())",17,15,3,3
243,keras.txt,https://api.github.com/repos/okly366/keras/commits/49386e8da49f0c63c467c28456c995ad24cc99fb,keras/backend/tensorflow_backend.py,https://github.com/okly366/keras/raw/49386e8da49f0c63c467c28456c995ad24cc99fb/keras/backend/tensorflow_backend.py,"         indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                   np.expand_dims(sparse_coo.col, 1)), 1)\n         # SparseTensor doesn't need initialization\n        return tf.SparseTensor(indices=indices,\n                               values=sparse_coo.data,\n                               shape=sparse_coo.shape)\n+        v._dims = len(sparse_coo.shape)\n     v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n     return v\n ","         indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                   np.expand_dims(sparse_coo.col, 1)), 1)\n         # SparseTensor doesn't need initialization\n-                               values=sparse_coo.data,\n        v = tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)\n        v._dims = len(sparse_coo.shape)\n        return v\n     v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n     return v\n ","        return tf.SparseTensor(indices=indices,\n                               values=sparse_coo.data,\n                               shape=sparse_coo.shape)","        v = tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)\n        v._dims = len(sparse_coo.shape)\n        return v",7,6,3,3
244,keras.txt,https://api.github.com/repos/okly366/keras/commits/49386e8da49f0c63c467c28456c995ad24cc99fb,keras/backend/tensorflow_backend.py,https://github.com/okly366/keras/raw/49386e8da49f0c63c467c28456c995ad24cc99fb/keras/backend/tensorflow_backend.py,"         if ndim:\n             shape = tuple([None for _ in range(ndim)])\n     if sparse:\n        tf_shape = tf.constant(np.array(list([0 for _ in range(len(shape))]),\n                                        dtype=np.int64))\n        x = tf.sparse_placeholder(dtype, shape=tf_shape, name=name)\n+        x._dims = len(shape)\n     else:\n         x = tf.placeholder(dtype, shape=shape, name=name)\n     x._keras_shape = shape","         if ndim:\n             shape = tuple([None for _ in range(ndim)])\n     if sparse:\n-                                        dtype=np.int64))\n        x = tf.sparse_placeholder(dtype, name=name)\n        x._dims = len(shape)\n     else:\n         x = tf.placeholder(dtype, shape=shape, name=name)\n     x._keras_shape = shape","        tf_shape = tf.constant(np.array(list([0 for _ in range(len(shape))]),\n                                        dtype=np.int64))\n        x = tf.sparse_placeholder(dtype, shape=tf_shape, name=name)","        x = tf.sparse_placeholder(dtype, name=name)\n        x._dims = len(shape)",7,6,3,2
275,keras.txt,https://api.github.com/repos/keunwoochoi/kapre/commits/76433544a6a01739dec33fbac43d4c81c520aae5,tests/test_time_frequency.py,https://github.com/keunwoochoi/kapre/raw/76433544a6a01739dec33fbac43d4c81c520aae5/tests/test_time_frequency.py,"     np.testing.assert_allclose(np.cos(a), np.cos(b), atol=atol)\n \n \n+    """"""Testing approximate phase.\n+    So makes more sense to count the number that are within tolerance\n+    count_failed = np.sum(np.abs(a - b) > atol)\n+        count_failed / a.size < acceptable_fail_ratio\n+\n def allclose_complex_numbers(a, b, atol=1e-3):\n     np.testing.assert_equal(np.shape(a), np.shape(b))\n     np.testing.assert_allclose(np.abs(a), np.abs(b), rtol=1e-5, atol=atol)","     np.testing.assert_allclose(np.cos(a), np.cos(b), atol=atol)\n \n \ndef assert_approx_phase(a, b, atol=1e-2, acceptable_fail_ratio=0.01):\n    """"""Testing approximate phase.\n    Tflite phase is approximate, some values will allways have a large error\n    So makes more sense to count the number that are within tolerance\n    """"""\n    count_failed = np.sum(np.abs(a - b) > atol)\n    assert (\n        count_failed / a.size < acceptable_fail_ratio\n    ), ""too many inaccuracte phase bins: {} bins out of {} incorrect"".format(count_failed, a.size)\n\n\n def allclose_complex_numbers(a, b, atol=1e-3):\n     np.testing.assert_equal(np.shape(a), np.shape(b))\n     np.testing.assert_allclose(np.abs(a), np.abs(b), rtol=1e-5, atol=atol)",,"def assert_approx_phase(a, b, atol=1e-2, acceptable_fail_ratio=0.01):\n    """"""Testing approximate phase.\n    Tflite phase is approximate, some values will allways have a large error\n    So makes more sense to count the number that are within tolerance\n    """"""\n    count_failed = np.sum(np.abs(a - b) > atol)\n    assert (\n        count_failed / a.size < acceptable_fail_ratio\n    ), ""too many inaccuracte phase bins: {} bins out of {} incorrect"".format(count_failed, a.size)",6,129,0,9
276,keras.txt,https://api.github.com/repos/PJmouraocs/keras/commits/8a50f5dfc80030b864ef24d6c562661c24fe7c2e,keras/callbacks.py,https://github.com/PJmouraocs/keras/raw/8a50f5dfc80030b864ef24d6c562661c24fe7c2e/keras/callbacks.py, from keras import backend as K\n from pkg_resources import parse_version\n \n+    import requests\n+    requests = None\n+if K.backend() == 'tensorflow':\n+\n \n class CallbackList(object):, from keras import backend as K\n from pkg_resources import parse_version\n \ntry:\n    import requests\nexcept ImportError:\n    requests = None\n\nif K.backend() == 'tensorflow':\n    import tensorflow as tf\n\n \n class CallbackList(object):,,try:\n    import requests\nexcept ImportError:\n    requests = None\nif K.backend() == 'tensorflow':\n    import tensorflow as tf,9,51,0,6
303,keras.txt,https://api.github.com/repos/mjdietzx/GAN-Sandbox/commits/814cb6191e818e51a636bfcc7867777e2da08238,gan.py,https://github.com/mjdietzx/GAN-Sandbox/raw/814cb6191e818e51a636bfcc7867777e2da08238/gan.py,"     # decoder: CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n     x = layers.Deconvolution2D(512, *kernel_size, output_shape=(None, 2, 2, 512), **conv_layer_keyword_args)(n_7)\n     x = add_common_layers(x)\n    x = layers.merge([n_6, x], mode='concat', concat_axis=3)\n \n     x = layers.Deconvolution2D(512, *kernel_size, output_shape=(None, 4, 4, 512), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x)\n    x = layers.merge([n_5, x], mode='concat', concat_axis=3)\n \n     x = layers.Deconvolution2D(512, *kernel_size, output_shape=(None, 8, 8, 512), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x)\n    x = layers.merge([n_4, x], mode='concat', concat_axis=3)\n \n     x = layers.Deconvolution2D(512, *kernel_size, output_shape=(None, 16, 16, 512), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x, dropout=False)\n    x = layers.merge([n_3, x], mode='concat', concat_axis=3)\n \n     x = layers.Deconvolution2D(256, *kernel_size, output_shape=(None, 32, 32, 256), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x, dropout=False)\n    x = layers.merge([n_2, x], mode='concat', concat_axis=3)\n \n     x = layers.Deconvolution2D(128, *kernel_size, output_shape=(None, 64, 64, 128), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x, dropout=False)\n    x = layers.merge([n_1, x], mode='concat', concat_axis=3)\n \n     x = layers.Deconvolution2D(64, *kernel_size, output_shape=(None, 128, 128, 64), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x, dropout=False)\n    x = layers.merge([n_0, x], mode='concat', concat_axis=3)\n \n     # number of feature maps => number of image channels\n     return layers.Deconvolution2D(img_channels, *kernel_size, output_shape=(None, img_height, img_width, img_channels),","     # decoder: CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n     x = layers.Deconvolution2D(512, *kernel_size, output_shape=(None, 2, 2, 512), **conv_layer_keyword_args)(n_7)\n     x = add_common_layers(x)\n    x = layers.merge([n_6, x], mode='concat', concat_axis=-1)\n \n     x = layers.Deconvolution2D(512, *kernel_size, output_shape=(None, 4, 4, 512), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x)\n    x = layers.merge([n_5, x], mode='concat', concat_axis=-1)\n \n     x = layers.Deconvolution2D(512, *kernel_size, output_shape=(None, 8, 8, 512), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x)\n    x = layers.merge([n_4, x], mode='concat', concat_axis=-1)\n \n     x = layers.Deconvolution2D(512, *kernel_size, output_shape=(None, 16, 16, 512), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x, dropout=False)\n    x = layers.merge([n_3, x], mode='concat', concat_axis=-1)\n \n     x = layers.Deconvolution2D(256, *kernel_size, output_shape=(None, 32, 32, 256), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x, dropout=False)\n    x = layers.merge([n_2, x], mode='concat', concat_axis=-1)\n \n     x = layers.Deconvolution2D(128, *kernel_size, output_shape=(None, 64, 64, 128), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x, dropout=False)\n    x = layers.merge([n_1, x], mode='concat', concat_axis=-1)\n \n     x = layers.Deconvolution2D(64, *kernel_size, output_shape=(None, 128, 128, 64), **conv_layer_keyword_args)(x)\n     x = add_common_layers(x, dropout=False)\n    x = layers.merge([n_0, x], mode='concat', concat_axis=-1)\n \n     # number of feature maps => number of image channels\n     return layers.Deconvolution2D(img_channels, *kernel_size, output_shape=(None, img_height, img_width, img_channels),","    x = layers.merge([n_6, x], mode='concat', concat_axis=3)\n    x = layers.merge([n_5, x], mode='concat', concat_axis=3)\n    x = layers.merge([n_4, x], mode='concat', concat_axis=3)\n    x = layers.merge([n_3, x], mode='concat', concat_axis=3)\n    x = layers.merge([n_2, x], mode='concat', concat_axis=3)\n    x = layers.merge([n_1, x], mode='concat', concat_axis=3)\n    x = layers.merge([n_0, x], mode='concat', concat_axis=3)","    x = layers.merge([n_6, x], mode='concat', concat_axis=-1)\n    x = layers.merge([n_5, x], mode='concat', concat_axis=-1)\n    x = layers.merge([n_4, x], mode='concat', concat_axis=-1)\n    x = layers.merge([n_3, x], mode='concat', concat_axis=-1)\n    x = layers.merge([n_2, x], mode='concat', concat_axis=-1)\n    x = layers.merge([n_1, x], mode='concat', concat_axis=-1)\n    x = layers.merge([n_0, x], mode='concat', concat_axis=-1)",23,23,7,7
327,keras.txt,https://api.github.com/repos/zoonn1788/TensorflowLiteDemo/commits/5247ebbe24465563bdd4ef46f1cecc34f256f76b,tensorflow/contrib/layers/python/layers/layers_test.py,https://github.com/zoonn1788/TensorflowLiteDemo/raw/5247ebbe24465563bdd4ef46f1cecc34f256f76b/tensorflow/contrib/layers/python/layers/layers_test.py,"     images = tf.random_uniform((5, height, width, 3), seed=1)\n     output = tf.contrib.layers.avg_pool2d(images, [3, 3],\n                                           outputs_collections='outputs')\n    output_collection = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collection.name, 'AvgPool2D')\n    self.assertEquals(output_collection.outputs, output)\n+    self.assertEquals(output_collected.alias, 'AvgPool2D')\n \n   def testCreateSquareAvgPool(self):\n     height, width = 3, 3","     images = tf.random_uniform((5, height, width, 3), seed=1)\n     output = tf.contrib.layers.avg_pool2d(images, [3, 3],\n                                           outputs_collections='outputs')\n-    self.assertEquals(output_collection.name, 'AvgPool2D')\n    output_collected = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collected.alias, 'AvgPool2D')\n    self.assertEquals(output_collected, output)\n \n   def testCreateSquareAvgPool(self):\n     height, width = 3, 3","    output_collection = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collection.name, 'AvgPool2D')\n    self.assertEquals(output_collection.outputs, output)","    output_collected = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collected.alias, 'AvgPool2D')\n    self.assertEquals(output_collected, output)",22,24,3,3
328,keras.txt,https://api.github.com/repos/zoonn1788/TensorflowLiteDemo/commits/5247ebbe24465563bdd4ef46f1cecc34f256f76b,tensorflow/contrib/layers/python/layers/layers_test.py,https://github.com/zoonn1788/TensorflowLiteDemo/raw/5247ebbe24465563bdd4ef46f1cecc34f256f76b/tensorflow/contrib/layers/python/layers/layers_test.py,"     height, width = 3, 3\n     images = tf.random_uniform((5, height, width, 3), seed=1)\n     with tf.name_scope('fe'):\n      conv = tf.contrib.layers.convolution2d(\n        images, 32, [3, 3], outputs_collections='outputs',\n        scope='Conv')\n    namedOutputs = tf.get_collection('outputs')[0]\n    self.assertEquals(namedOutputs.name, 'fe/Conv')\n+                                             outputs_collections='outputs',\n+    output_collected = tf.get_collection('outputs')[0]\n+    self.assertEquals(output_collected, conv)\n \n   def testCreateConvWithoutActivation(self):\n     height, width = 3, 3","     height, width = 3, 3\n     images = tf.random_uniform((5, height, width, 3), seed=1)\n     with tf.name_scope('fe'):\n-        images, 32, [3, 3], outputs_collections='outputs',\n-    namedOutputs = tf.get_collection('outputs')[0]\n      conv = tf.contrib.layers.convolution2d(images, 32, [3, 3],\n                                             outputs_collections='outputs',\n                                             scope='Conv')\n    output_collected = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collected.alias, 'fe/Conv')\n    self.assertEquals(output_collected, conv)\n \n   def testCreateConvWithoutActivation(self):\n     height, width = 3, 3","      conv = tf.contrib.layers.convolution2d(\n        images, 32, [3, 3], outputs_collections='outputs',\n        scope='Conv')\n    namedOutputs = tf.get_collection('outputs')[0]\n    self.assertEquals(namedOutputs.name, 'fe/Conv')","      conv = tf.contrib.layers.convolution2d(images, 32, [3, 3],\n                                             outputs_collections='outputs',\n                                             scope='Conv')\n    output_collected = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collected.alias, 'fe/Conv')\n    self.assertEquals(output_collected, conv)",22,24,5,6
329,keras.txt,https://api.github.com/repos/zoonn1788/TensorflowLiteDemo/commits/5247ebbe24465563bdd4ef46f1cecc34f256f76b,tensorflow/contrib/layers/python/layers/layers_test.py,https://github.com/zoonn1788/TensorflowLiteDemo/raw/5247ebbe24465563bdd4ef46f1cecc34f256f76b/tensorflow/contrib/layers/python/layers/layers_test.py,"     height, width = 3, 3\n     inputs = tf.random_uniform((5, height * width * 3), seed=1)\n     with tf.name_scope('fe'):\n      fc = tf.contrib.layers.fully_connected(\n        inputs, 7, outputs_collections='outputs',\n        scope='fc')\n    namedOutputs = tf.get_collection('outputs')[0]\n    self.assertEquals(namedOutputs.name, 'fe/fc')\n+                                             outputs_collections='outputs',\n+    output_collected = tf.get_collection('outputs')[0]\n+    self.assertEquals(output_collected, fc)\n \n   def testCreateFcCreatesWeightsAndBiasesVars(self):\n     height, width = 3, 3","     height, width = 3, 3\n     inputs = tf.random_uniform((5, height * width * 3), seed=1)\n     with tf.name_scope('fe'):\n-        inputs, 7, outputs_collections='outputs',\n-    namedOutputs = tf.get_collection('outputs')[0]\n      fc = tf.contrib.layers.fully_connected(inputs, 7,\n                                             outputs_collections='outputs',\n                                             scope='fc')\n    output_collected = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collected.alias, 'fe/fc')\n    self.assertEquals(output_collected, fc)\n \n   def testCreateFcCreatesWeightsAndBiasesVars(self):\n     height, width = 3, 3","      fc = tf.contrib.layers.fully_connected(\n        inputs, 7, outputs_collections='outputs',\n        scope='fc')\n    namedOutputs = tf.get_collection('outputs')[0]\n    self.assertEquals(namedOutputs.name, 'fe/fc')","      fc = tf.contrib.layers.fully_connected(inputs, 7,\n                                             outputs_collections='outputs',\n                                             scope='fc')\n    output_collected = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collected.alias, 'fe/fc')\n    self.assertEquals(output_collected, fc)",22,24,5,6
330,keras.txt,https://api.github.com/repos/zoonn1788/TensorflowLiteDemo/commits/5247ebbe24465563bdd4ef46f1cecc34f256f76b,tensorflow/contrib/layers/python/layers/layers_test.py,https://github.com/zoonn1788/TensorflowLiteDemo/raw/5247ebbe24465563bdd4ef46f1cecc34f256f76b/tensorflow/contrib/layers/python/layers/layers_test.py,"     images = tf.random_uniform((5, height, width, 3), seed=1)\n     output = tf.contrib.layers.max_pool2d(images, [3, 3],\n                                           outputs_collections='outputs')\n    outputs_collection = tf.get_collection('outputs')[0]\n    self.assertEquals(outputs_collection.name, 'MaxPool2D')\n    self.assertEquals(outputs_collection.outputs, output)\n+    self.assertEquals(output_collected.alias, 'MaxPool2D')\n \n   def testCreateSquareMaxPool(self):\n     height, width = 3, 3","     images = tf.random_uniform((5, height, width, 3), seed=1)\n     output = tf.contrib.layers.max_pool2d(images, [3, 3],\n                                           outputs_collections='outputs')\n-    self.assertEquals(outputs_collection.name, 'MaxPool2D')\n    output_collected = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collected.alias, 'MaxPool2D')\n    self.assertEquals(output_collected, output)\n \n   def testCreateSquareMaxPool(self):\n     height, width = 3, 3","    outputs_collection = tf.get_collection('outputs')[0]\n    self.assertEquals(outputs_collection.name, 'MaxPool2D')\n    self.assertEquals(outputs_collection.outputs, output)","    output_collected = tf.get_collection('outputs')[0]\n    self.assertEquals(output_collected.alias, 'MaxPool2D')\n    self.assertEquals(output_collected, output)",22,24,3,3
333,keras.txt,https://api.github.com/repos/zhuyawen/keras/commits/8a50f5dfc80030b864ef24d6c562661c24fe7c2e,keras/callbacks.py,https://github.com/zhuyawen/keras/raw/8a50f5dfc80030b864ef24d6c562661c24fe7c2e/keras/callbacks.py, from keras import backend as K\n from pkg_resources import parse_version\n \n+    import requests\n+    requests = None\n+if K.backend() == 'tensorflow':\n+\n \n class CallbackList(object):, from keras import backend as K\n from pkg_resources import parse_version\n \ntry:\n    import requests\nexcept ImportError:\n    requests = None\n\nif K.backend() == 'tensorflow':\n    import tensorflow as tf\n\n \n class CallbackList(object):,,try:\n    import requests\nexcept ImportError:\n    requests = None\nif K.backend() == 'tensorflow':\n    import tensorflow as tf,9,51,0,6
367,keras.txt,https://api.github.com/repos/saturn-lab/audioNet/commits/a5a135fe55ef177e0d9fb97b5534b8fb14919f43,webfront.py,https://github.com/saturn-lab/audioNet/raw/a5a135fe55ef177e0d9fb97b5534b8fb14919f43/webfront.py,"#!/opt/anaconda3/bin/python\n # -*- coding:utf-8 -*-\n \nimport os, sys, subprocess\n+from wavReader import readWav\n+import sys\n+import numpy as np\n from flask import Flask, request, redirect, flash\n from werkzeug.utils import secure_filename\nimport numpy\n \n sys.path.append('augmentation' + os.sep)\n \nfrom wavReader import readWav\nfrom model import KerasModel\n \n UPLOAD_FOLDER = '.' + os.sep + 'tmp'\nFFMPEG_PATH='.' + os.sep + 'ffmpeg' + os.sep + 'bin' + os.sep + 'ffmpeg'\nMODEL_ID=60\n \n app = Flask(__name__)\n app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n \n def predict(wavfile, modelfile):\n     spl, wav = readWav(wavfile)\n     wav = wav.reshape([1, -1, 1, 1])"," # -*- coding:utf-8 -*-\n \nfrom model import KerasModel\nfrom wavReader import readWav\nimport os\nimport sys\nimport subprocess\nimport numpy as np\n from flask import Flask, request, redirect, flash\n from werkzeug.utils import secure_filename\nfrom user_config import FFMPEG_PATH\n \n sys.path.append('augmentation' + os.sep)\n \n-from model import KerasModel\n \n UPLOAD_FOLDER = '.' + os.sep + 'tmp'\n-MODEL_ID=60\nMODEL_ID = 60\n \n app = Flask(__name__)\n app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n \n\n def predict(wavfile, modelfile):\n     spl, wav = readWav(wavfile)\n     wav = wav.reshape([1, -1, 1, 1])","#!/opt/anaconda3/bin/python\nimport os, sys, subprocess\nimport numpy\nfrom wavReader import readWav\nfrom model import KerasModel\nFFMPEG_PATH='.' + os.sep + 'ffmpeg' + os.sep + 'bin' + os.sep + 'ffmpeg'\nMODEL_ID=60",from model import KerasModel\nfrom wavReader import readWav\nimport os\nimport sys\nimport subprocess\nimport numpy as np\nfrom user_config import FFMPEG_PATH\nMODEL_ID = 60,18,26,7,8
371,keras.txt,https://api.github.com/repos/CrisSherban/BrainPad/commits/8443cfd62274eb20c1696ddbfde423b82bfec223,training.py,https://github.com/CrisSherban/BrainPad/raw/8443cfd62274eb20c1696ddbfde423b82bfec223/training.py," # https://github.com/Sentdex/BCI\n \n import tensorflow as tf\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n+from keras.models import Sequential\n+from keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n+# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n "," # https://github.com/Sentdex/BCI\n# also check out his version, he uses Conv1D nets\n \n import tensorflow as tf\n-from tensorflow.keras.models import Sequential\n-from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom colors import red, green\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \n-print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n ","from tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom sklearn.preprocessing import MinMaxScaler\nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))","# also check out his version, he uses Conv1D nets\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom colors import red, green\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))",108,99,7,8
372,keras.txt,https://api.github.com/repos/CrisSherban/BrainPad/commits/8443cfd62274eb20c1696ddbfde423b82bfec223,training.py,https://github.com/CrisSherban/BrainPad/raw/8443cfd62274eb20c1696ddbfde423b82bfec223/training.py," # https://github.com/Sentdex/BCI\n \n import tensorflow as tf\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n+from keras.models import Sequential\n+from keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n+# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n "," # https://github.com/Sentdex/BCI\n# also check out his version, he uses Conv1D nets\n \n import tensorflow as tf\n-from tensorflow.keras.models import Sequential\n-from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom colors import red, green\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \n-print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n ","from tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom sklearn.preprocessing import MinMaxScaler\nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))","# also check out his version, he uses Conv1D nets\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom colors import red, green\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))",108,99,7,8
373,keras.txt,https://api.github.com/repos/CrisSherban/BrainPad/commits/8443cfd62274eb20c1696ddbfde423b82bfec223,training.py,https://github.com/CrisSherban/BrainPad/raw/8443cfd62274eb20c1696ddbfde423b82bfec223/training.py," # https://github.com/Sentdex/BCI\n \n import tensorflow as tf\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n+from keras.models import Sequential\n+from keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n+# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n "," # https://github.com/Sentdex/BCI\n# also check out his version, he uses Conv1D nets\n \n import tensorflow as tf\n-from tensorflow.keras.models import Sequential\n-from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom colors import red, green\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \n-print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n ","from tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom sklearn.preprocessing import MinMaxScaler\nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))","# also check out his version, he uses Conv1D nets\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom colors import red, green\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))",108,99,7,8
374,keras.txt,https://api.github.com/repos/CrisSherban/BrainPad/commits/8443cfd62274eb20c1696ddbfde423b82bfec223,training.py,https://github.com/CrisSherban/BrainPad/raw/8443cfd62274eb20c1696ddbfde423b82bfec223/training.py," # https://github.com/Sentdex/BCI\n \n import tensorflow as tf\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n+from keras.models import Sequential\n+from keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n+# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n "," # https://github.com/Sentdex/BCI\n# also check out his version, he uses Conv1D nets\n \n import tensorflow as tf\n-from tensorflow.keras.models import Sequential\n-from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom colors import red, green\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \n-print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n ","from tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom sklearn.preprocessing import MinMaxScaler\nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))","# also check out his version, he uses Conv1D nets\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom colors import red, green\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))",108,99,7,8
375,keras.txt,https://api.github.com/repos/CrisSherban/BrainPad/commits/8443cfd62274eb20c1696ddbfde423b82bfec223,training.py,https://github.com/CrisSherban/BrainPad/raw/8443cfd62274eb20c1696ddbfde423b82bfec223/training.py," # https://github.com/Sentdex/BCI\n \n import tensorflow as tf\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n+from keras.models import Sequential\n+from keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n+# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n "," # https://github.com/Sentdex/BCI\n# also check out his version, he uses Conv1D nets\n \n import tensorflow as tf\n-from tensorflow.keras.models import Sequential\n-from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom colors import red, green\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \n-print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n ","from tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom sklearn.preprocessing import MinMaxScaler\nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))","# also check out his version, he uses Conv1D nets\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom colors import red, green\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))",108,99,7,8
376,keras.txt,https://api.github.com/repos/CrisSherban/BrainPad/commits/8443cfd62274eb20c1696ddbfde423b82bfec223,training.py,https://github.com/CrisSherban/BrainPad/raw/8443cfd62274eb20c1696ddbfde423b82bfec223/training.py," # https://github.com/Sentdex/BCI\n \n import tensorflow as tf\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n+from keras.models import Sequential\n+from keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n+# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n "," # https://github.com/Sentdex/BCI\n# also check out his version, he uses Conv1D nets\n \n import tensorflow as tf\n-from tensorflow.keras.models import Sequential\n-from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom colors import red, green\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \n-print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n ","from tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom sklearn.preprocessing import MinMaxScaler\nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))","# also check out his version, he uses Conv1D nets\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom colors import red, green\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))",108,99,7,8
377,keras.txt,https://api.github.com/repos/CrisSherban/BrainPad/commits/8443cfd62274eb20c1696ddbfde423b82bfec223,training.py,https://github.com/CrisSherban/BrainPad/raw/8443cfd62274eb20c1696ddbfde423b82bfec223/training.py," # https://github.com/Sentdex/BCI\n \n import tensorflow as tf\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n+from keras.models import Sequential\n+from keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n+# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n "," # https://github.com/Sentdex/BCI\n# also check out his version, he uses Conv1D nets\n \n import tensorflow as tf\n-from tensorflow.keras.models import Sequential\n-from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\n from matplotlib import pyplot as plt\nfrom colors import red, green\n import numpy as np\n import time\n import os\n \n # os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n \n-print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))\n \n ACTIONS = [""left"", ""right"", ""none""]\n ","from tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom sklearn.preprocessing import MinMaxScaler\nprint(tf.__version__)\nprint(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))","# also check out his version, he uses Conv1D nets\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom colors import red, green\n# print(tf.__version__)\n# print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))",108,99,7,8
394,keras.txt,https://api.github.com/repos/BraunMichael/MultiResUNet-Keras-Dragonfly4.1/commits/4a6f06f06d6a90eabfbdc48ec549d351dc012185,keras/datasets/reuters.py,https://github.com/BraunMichael/MultiResUNet-Keras-Dragonfly4.1/raw/4a6f06f06d6a90eabfbdc48ec549d351dc012185/keras/datasets/reuters.py,"         raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n \n     path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters.npz')\n    npzfile = np.load(path)\n    xs = npzfile['x']\n    labels = npzfile['y']\n    npzfile.close()\n+        xs, labels = f['x'], f['y']\n \n     np.random.seed(seed)\n     np.random.shuffle(xs)","         raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n \n     path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters.npz')\n-    xs = npzfile['x']\n-    npzfile.close()\n    with np.load(path) as f:\n        xs, labels = f['x'], f['y']\n \n     np.random.seed(seed)\n     np.random.shuffle(xs)",    npzfile = np.load(path)\n    xs = npzfile['x']\n    labels = npzfile['y']\n    npzfile.close(),"    with np.load(path) as f:\n        xs, labels = f['x'], f['y']",27,10,4,2
454,keras.txt,https://api.github.com/repos/waltYeh/onnx2keras/commits/1c14a3ef3ac788b5e347ef3bdd75c756075530e1,onnx2keras/reshape_layers.py,https://github.com/waltYeh/onnx2keras/raw/1c14a3ef3ac788b5e347ef3bdd75c756075530e1/onnx2keras/reshape_layers.py,"             import tensorflow as tf\n             return tf.concat(x, axis=axis)\n \n        lambda_layer = keras.layers.Lambda(target_layer, name=node_name)\n        layers[node_name] = lambda_layer([ensure_tf_type(layers[node.input[i]], layers[list(layers)[0]]) for i in range(len(node.input))])\n+        layers[node_name] = lambda_layer([ensure_tf_type(layers[node.input[i]], layers[list(layers)[0]], name=""%s_const"" % keras_name) for i in range(len(node.input))])\n \n        \n def convert_reshape(node, params, layers, node_name, keras_name):\n     Convert reshape.","             import tensorflow as tf\n             return tf.concat(x, axis=axis)\n \n-        layers[node_name] = lambda_layer([ensure_tf_type(layers[node.input[i]], layers[list(layers)[0]]) for i in range(len(node.input))])\n        lambda_layer = keras.layers.Lambda(target_layer, name=keras_name)\n        layers[node_name] = lambda_layer([ensure_tf_type(layers[node.input[i]], layers[list(layers)[0]], name=""%s_const"" % keras_name) for i in range(len(node.input))])\n\n \n def convert_reshape(node, params, layers, node_name, keras_name):\n     Convert reshape.","        lambda_layer = keras.layers.Lambda(target_layer, name=node_name)\n        layers[node_name] = lambda_layer([ensure_tf_type(layers[node.input[i]], layers[list(layers)[0]]) for i in range(len(node.input))])\n        ","        lambda_layer = keras.layers.Lambda(target_layer, name=keras_name)\n        layers[node_name] = lambda_layer([ensure_tf_type(layers[node.input[i]], layers[list(layers)[0]], name=""%s_const"" % keras_name) for i in range(len(node.input))])",7,7,3,2
470,keras.txt,https://api.github.com/repos/zhymirt/keras_NN/commits/1fa6d8f2ade74cb2bb3d11201e8bafa68f3f085b,sine_tsgan.py,https://github.com/zhymirt/keras_NN/raw/1fa6d8f2ade74cb2bb3d11201e8bafa68f3f085b/sine_tsgan.py,"     image_shape, flattened_image_shape = (51, 1), (51,)\n     discriminator_1 = keras.Sequential([\n         layers.Reshape((1,)+image_shape, input_shape=image_shape),\n        layers.Conv2D(16, (1, 5), strides=(1, 3)),\n         layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(16, (1, 3), strides=(1, 2)),\n+        layers.LeakyReLU(alpha=0.2),\n         layers.LeakyReLU(alpha=0.2),\n        # layers.Conv2D(16, (1, 3), strides=(1, 2)),\n        # layers.LeakyReLU(alpha=0.2),\n         layers.Conv2D(1, (1, 3)),\n         layers.LeakyReLU(alpha=0.2),\n         layers.Flatten(),","     image_shape, flattened_image_shape = (51, 1), (51,)\n     discriminator_1 = keras.Sequential([\n         layers.Reshape((1,)+image_shape, input_shape=image_shape),\n        layers.Conv2D(64, (1, 5), strides=(1, 1)),\n         layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, (1, 3), strides=(1, 1)),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(256, (1, 3), strides=(1, 1)),\n         layers.LeakyReLU(alpha=0.2),\n-        # layers.LeakyReLU(alpha=0.2),\n         layers.Conv2D(1, (1, 3)),\n         layers.LeakyReLU(alpha=0.2),\n         layers.Flatten(),","        layers.Conv2D(16, (1, 5), strides=(1, 3)),\n        layers.Conv2D(16, (1, 3), strides=(1, 2)),\n        # layers.Conv2D(16, (1, 3), strides=(1, 2)),\n        # layers.LeakyReLU(alpha=0.2),","        layers.Conv2D(64, (1, 5), strides=(1, 1)),\n        layers.Conv2D(128, (1, 3), strides=(1, 1)),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(256, (1, 3), strides=(1, 1)),",6,7,4,4
471,keras.txt,https://api.github.com/repos/francescodonato/GPFlow_Keras/commits/d6883d26b557cbeeaceba38643bf5b98819fbed3,gpflow/models/sgpr.py,https://github.com/francescodonato/GPFlow_Keras/raw/d6883d26b557cbeeaceba38643bf5b98819fbed3/gpflow/models/sgpr.py,"         LB = tf.cholesky(Kuu + self.likelihood.variance ** -1.0 * tf.matmul(Kuf, Kuf, transpose_b=True))\n \n         LinvKuf = tf.matrix_triangular_solve(L, Kuf, lower=True)\n        c = tf.reduce_sum(Kdiag) - tf.reduce_sum(LinvKuf ** 2.0)  # Using the Trace bound, from Titsias' presentation\n+        c = tf.reduce_sum(Kdiag) - tf.reduce_sum(LinvKuf ** 2.0)\n         # Kff = self.kern.K(self.X)\n         # Qff = tf.matmul(Kuf, LinvKuf, transpose_a=True)\n        # c = tf.reduce_max(tf.reduce_sum(tf.abs(Kff - Qff), 0))  # Alternative bound on max eigenval\n+        # Alternative bound on max eigenval:\n         corrected_noise = self.likelihood.variance + c\n \n         const = -0.5 * num_data * tf.log(2 * np.pi * self.likelihood.variance)","         LB = tf.cholesky(Kuu + self.likelihood.variance ** -1.0 * tf.matmul(Kuf, Kuf, transpose_b=True))\n \n         LinvKuf = tf.matrix_triangular_solve(L, Kuf, lower=True)\n        # Using the Trace bound, from Titsias' presentation\n        c = tf.reduce_sum(Kdiag) - tf.reduce_sum(LinvKuf ** 2.0)\n         # Kff = self.kern.K(self.X)\n         # Qff = tf.matmul(Kuf, LinvKuf, transpose_a=True)\n\n        # Alternative bound on max eigenval:\n        # c = tf.reduce_max(tf.reduce_sum(tf.abs(Kff - Qff), 0))\n         corrected_noise = self.likelihood.variance + c\n \n         const = -0.5 * num_data * tf.log(2 * np.pi * self.likelihood.variance)","        c = tf.reduce_sum(Kdiag) - tf.reduce_sum(LinvKuf ** 2.0)  # Using the Trace bound, from Titsias' presentation\n        # c = tf.reduce_max(tf.reduce_sum(tf.abs(Kff - Qff), 0))  # Alternative bound on max eigenval","        # Using the Trace bound, from Titsias' presentation\n        c = tf.reduce_sum(Kdiag) - tf.reduce_sum(LinvKuf ** 2.0)\n        # Alternative bound on max eigenval:\n        # c = tf.reduce_max(tf.reduce_sum(tf.abs(Kff - Qff), 0))",9,13,2,4
473,keras.txt,https://api.github.com/repos/marcinmozejko/keras_with_advanced_activation_changed/commits/5430844453f5153f16dbd9d762d6a5a4106ba23f,keras/preprocessing/image.py,https://github.com/marcinmozejko/keras_with_advanced_activation_changed/raw/5430844453f5153f16dbd9d762d6a5a4106ba23f/keras/preprocessing/image.py," \n def array_to_img(x, dim_ordering='default', scale=True):\n     from PIL import Image\n+    if x.ndim != 3:\n+                         'Got array with shape:', x.shape)\n     if dim_ordering == 'default':\n         dim_ordering = K.image_dim_ordering()\n+        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+    # Original Numpy array x has format (height, width, channel)\n+    # but target PIL image has format (width, height, channel)\n     if dim_ordering == 'th':\n         x = x.transpose(1, 2, 0)\n     if scale:"," \n def array_to_img(x, dim_ordering='default', scale=True):\n     from PIL import Image\n    x = np.asarray(x)\n    if x.ndim != 3:\n        raise ValueError('Expected image array to have rank 3 (single image). '\n                         'Got array with shape:', x.shape)\n\n     if dim_ordering == 'default':\n         dim_ordering = K.image_dim_ordering()\n    if dim_ordering not in {'th', 'tf'}:\n        raise ValueError('Invalid dim_ordering:', dim_ordering)\n\n    # Original Numpy array x has format (height, width, channel)\n    # or (channel, height, width)\n    # but target PIL image has format (width, height, channel)\n     if dim_ordering == 'th':\n         x = x.transpose(1, 2, 0)\n     if scale:",,"    x = np.asarray(x)\n    if x.ndim != 3:\n        raise ValueError('Expected image array to have rank 3 (single image). '\n                         'Got array with shape:', x.shape)\n    if dim_ordering not in {'th', 'tf'}:\n        raise ValueError('Invalid dim_ordering:', dim_ordering)\n    # Original Numpy array x has format (height, width, channel)\n    # or (channel, height, width)\n    # but target PIL image has format (width, height, channel)",34,100,0,9
477,keras.txt,https://api.github.com/repos/Arjuno55/Advanced-Deep-Learning-With-Keras/commits/5e674bf6dfdbffcedd346b9facfc8c5fc3865b9a,chapter6-disentangled-gan/infogan-mnist-6.1.1.py,https://github.com/Arjuno55/Advanced-Deep-Learning-With-Keras/raw/5e674bf6dfdbffcedd346b9facfc8c5fc3865b9a/chapter6-disentangled-gan/infogan-mnist-6.1.1.py,"             params\n     # the generator image is saved every 500 steps\n     save_interval = 500\n+    code_std = 0.5\n     # noise vector to see how the generator output \n     # evolves during training\n     noise_input = np.random.uniform(-1.0,\n                                     1.0,\n                                     size=[16, latent_size])\n     # random class labels and codes\n     noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n    noise_code1 = np.random.normal(scale=0.5, size=[16, 1])\n    noise_code2 = np.random.normal(scale=0.5, size=[16, 1])\n+    noise_code2 = np.random.normal(scale=code_std, size=[16, 1])\n     # number of elements in train dataset\n     train_size = x_train.shape[0]\n     print(model_name,\n           ""Labels for generated images: "",\n           np.argmax(noise_label, axis=1))\n\n     for i in range(train_steps):\n         # train the discriminator for 1 batch\n         # 1 batch of real (label=1.0) and fake images (label=0.0)","             params\n     # the generator image is saved every 500 steps\n     save_interval = 500\n    # code standard deviation\n    code_std = 0.5\n     # noise vector to see how the generator output \n     # evolves during training\n     noise_input = np.random.uniform(-1.0,\n                                     1.0,\n                                     size=[16, latent_size])\n     # random class labels and codes\n     noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n-    noise_code2 = np.random.normal(scale=0.5, size=[16, 1])\n    noise_code1 = np.random.normal(scale=code_std, size=[16, 1])\n    noise_code2 = np.random.normal(scale=code_std, size=[16, 1])\n     # number of elements in train dataset\n     train_size = x_train.shape[0]\n     print(model_name,\n           ""Labels for generated images: "",\n           np.argmax(noise_label, axis=1))\n     for i in range(train_steps):\n         # train the discriminator for 1 batch\n         # 1 batch of real (label=1.0) and fake images (label=0.0)","    noise_code1 = np.random.normal(scale=0.5, size=[16, 1])\n    noise_code2 = np.random.normal(scale=0.5, size=[16, 1])","    # code standard deviation\n    code_std = 0.5\n    noise_code1 = np.random.normal(scale=code_std, size=[16, 1])\n    noise_code2 = np.random.normal(scale=code_std, size=[16, 1])",21,24,2,4
478,keras.txt,https://api.github.com/repos/suleiwin/keras/commits/d68ca4336428fdd5c16b16409b1417bb9af2043f,keras_retinanet/losses.py,https://github.com/suleiwin/keras/raw/d68ca4336428fdd5c16b16409b1417bb9af2043f/keras_retinanet/losses.py,"             regression_diff - 0.5 / sigma_squared\n         )\n \n        # normalise by the number of positive and negative anchors for each entry in the minibatch\n        regression_loss = regression_loss / divisor\n\n         # filter out ""ignore"" anchors\n         indices         = backend.where(keras.backend.equal(anchor_state, 1))\n         regression_loss = backend.gather_nd(regression_loss, indices)\n \n        # divide by the size of the minibatch\n        regression_loss = keras.backend.sum(regression_loss) / keras.backend.cast(keras.backend.shape(y_true)[0], keras.backend.floatx())\n+        normalizer = keras.backend.maximum(1, keras.backend.shape(indices)[0])\n \n        return regression_loss\n \n     return _smooth_l1","             regression_diff - 0.5 / sigma_squared\n         )\n \n-        regression_loss = regression_loss / divisor\n         # filter out ""ignore"" anchors\n         indices         = backend.where(keras.backend.equal(anchor_state, 1))\n         regression_loss = backend.gather_nd(regression_loss, indices)\n \n-        regression_loss = keras.backend.sum(regression_loss) / keras.backend.cast(keras.backend.shape(y_true)[0], keras.backend.floatx())\n        # compute the normalizer: the number of positive anchors\n        normalizer = keras.backend.maximum(1, keras.backend.shape(indices)[0])\n        normalizer = keras.backend.cast(keras.backend.maximum(1, normalizer), dtype=keras.backend.floatx())\n \n        return keras.backend.sum(regression_loss) / normalizer\n \n     return _smooth_l1","        # normalise by the number of positive and negative anchors for each entry in the minibatch\n        regression_loss = regression_loss / divisor\n        # divide by the size of the minibatch\n        regression_loss = keras.backend.sum(regression_loss) / keras.backend.cast(keras.backend.shape(y_true)[0], keras.backend.floatx())\n        return regression_loss","        # compute the normalizer: the number of positive anchors\n        normalizer = keras.backend.maximum(1, keras.backend.shape(indices)[0])\n        normalizer = keras.backend.cast(keras.backend.maximum(1, normalizer), dtype=keras.backend.floatx())\n        return keras.backend.sum(regression_loss) / normalizer",33,10,5,4
